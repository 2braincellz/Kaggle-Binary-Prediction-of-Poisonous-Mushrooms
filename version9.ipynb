{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from xgboost import XGBClassifier\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_non_alpha_with_nan(df, categories):\n",
    "    # cols_to_filter = ['cap-shape', 'cap-surface', 'cap-color', \n",
    "    #                   'does-bruise-or-bleed', 'gill-attachment', \n",
    "    #                   'gill-spacing', 'gill-color', 'stem-surface', \n",
    "    #                   'stem-color', 'has-ring', 'ring-type', 'habitat', 'stem-root', 'veil-type', 'veil-color', 'spore-print-color']\n",
    "\n",
    "    cols_to_filter = categories\n",
    "    \n",
    "\n",
    "    alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', \n",
    "                     'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    # col_values = {}\n",
    "    # for col in cols_to_filter:\n",
    "    #     value_counts = train[col].value_counts()# ? ONLY Based on trained dataset\n",
    "    #     col_values[col] = value_counts[value_counts > 10].index.values.tolist()\n",
    "\n",
    "\n",
    "    # def filter_alpha(value, value_list_no_outliers):\n",
    "    #     if isinstance(value, str):\n",
    "    #         return value if len(value) == 1 and value in value_list_no_outliers and value in alphabet_list else np.nan # if value is a single character\n",
    "        \n",
    "    #     return np.nan\n",
    "    \n",
    "    # for col in cols_to_filter:\n",
    "    #     df[col] = df[col].apply(lambda x : filter_alpha(x, col_values[col]))\n",
    "\n",
    "\n",
    "    # * Customized feature engineering\n",
    "    features_dict = {\n",
    "        'cap_shape': ['x', 'f', 's', 'b', 'o', 'p', 'c'],\n",
    "        'cap_surface': ['t', 's', 'y', 'h', 'g', 'd', 'k', 'e', 'i', 'w', 'l'],\n",
    "        'cap_color': ['n', 'y', 'w', 'g', 'e', 'o', 'p', 'r', 'u', 'b', 'k', 'l'],\n",
    "        'does_bruise_or_bleed': ['f', 't'],\n",
    "        'gill_attachment': ['a', 'd', 'x', 'e', 's', 'p', 'f'],\n",
    "        'gill_spacing': ['c', 'd', 'f'],\n",
    "        'gill_color': ['w', 'n', 'y', 'p', 'g', 'o', 'k', 'f', 'r', 'e', 'b', 'u'],\n",
    "        'stem_root': ['b', 's', 'r', 'c', 'f'],\n",
    "        'stem_surface': ['s', 'y', 'i', 't', 'g', 'k', 'h', 'f'],\n",
    "        'stem_color': ['w', 'n', 'y', 'g', 'o', 'e', 'u', 'p', 'k', 'r', 'l', 'b', 'f'],\n",
    "        'veil_type': ['u'],\n",
    "        'veil_color': ['w', 'y', 'n', 'u', 'k', 'e'],\n",
    "        'has_ring': ['f', 't'],\n",
    "        'ring_type': ['f', 'e', 'z', 'l', 'r', 'p', 'g', 'm'],\n",
    "        'spore_print_color': ['k', 'p', 'w', 'n', 'r', 'u', 'g'],\n",
    "        'habitat': ['d', 'g', 'l', 'm', 'h', 'w', 'p', 'u'],\n",
    "        'season': ['a', 'u', 'w', 's']\n",
    "    }\n",
    "\n",
    "\n",
    "    for classes, cols  in zip(features_dict.keys(), cols_to_filter):\n",
    "        # df.loc[(~df[cols].isin(features_dict[classes])) & pd.notna(df[cols]), cols] = 'missing'\n",
    "        df.loc[~df[cols].isin(features_dict[classes]), cols] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_train_and_test_data(df_train, target, df_test, kaggle_test, num_cols, cat_cols, variable):\n",
    "\n",
    "    numeric_transformer = Pipeline(steps = [\n",
    "        ('imputer', KNNImputer(n_neighbors = 3))\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps = [\n",
    "        # ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "        # ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        # ('Target', TargetEncoder(smoothing=variable)),\n",
    "        ('OneHot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "\n",
    "        # ('adjust', FunctionTransformer(lambda x : x + 1)) # * Adjust function\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', numeric_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)\n",
    "        ],\n",
    "        remainder = 'passthrough'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # * Target Encoding\n",
    "    # train_te = preprocessor.fit_transform(df_train[all_columns], target)\n",
    "    # test_te = preprocessor.transform(df_test[all_columns])\n",
    "    # val_te = preprocessor.transform(df_validation[all_columns])\n",
    "\n",
    "    all_columns = num_cols + cat_cols\n",
    "\n",
    "    train_te = preprocessor.fit_transform(df_train[all_columns])\n",
    "    test_te = preprocessor.transform(df_test[all_columns])\n",
    "\n",
    "\n",
    "    feature_names_out = preprocessor.get_feature_names_out()\n",
    "\n",
    "    smoothing['feature names'] = feature_names_out\n",
    "\n",
    "\n",
    "    print(f\"All Columns {feature_names_out}\")\n",
    "\n",
    "    print(f\"Train Transformed = {train_te}\")\n",
    "\n",
    "    # smoothing['categories'] = \n",
    "\n",
    "    df_train_transformed = pd.DataFrame(train_te, columns = feature_names_out)\n",
    "    df_test_transformed = pd.DataFrame(test_te, columns = feature_names_out)\n",
    "\n",
    "    # print(preprocessor['cat'].get_feature_names_out())\n",
    "\n",
    "    # df_transformed = pd.DataFrame(preprocessor.fit_transform(df[num_cols + cat_cols], df['class']), columns = num_cols + cat_cols)\n",
    "\n",
    "    df_train_final = df_train_transformed\n",
    "    df_test_final = df_test_transformed\n",
    "\n",
    "\n",
    "    kaggle_test_te = preprocessor.transform(kaggle_test[all_columns])\n",
    "    kaggle_test_final = pd.DataFrame(kaggle_test_te, columns = feature_names_out)\n",
    "\n",
    "\n",
    "    return df_train_final, df_test_final, kaggle_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def find_train_combinations(train, cat_cols, num_cols):\n",
    "    \n",
    "    \n",
    "    all_columns = cat_cols + num_cols\n",
    "\n",
    "    # ? returning features from train_combinations with correlations greater than the mean of the original\n",
    "    \n",
    "    ord_enc = LabelEncoder()\n",
    "    train['class'] = ord_enc.fit_transform(train['class'])\n",
    "\n",
    "    corr_matrix = train.corr()\n",
    "    \n",
    "    threshold = abs(corr_matrix['class']).sort_values(ascending=False).mean()\n",
    "    print(f\" Mean Correlation of Original Data {threshold}\")\n",
    "\n",
    "\n",
    "    filtered_cols = [col for col in all_columns if col != 'class']\n",
    "    print(filtered_cols)\n",
    "    print(train.columns)\n",
    "    combinations = itertools.combinations(filtered_cols, 2)\n",
    "    print(combinations)\n",
    "\n",
    "    train_combinations = train['class'].to_frame()\n",
    "\n",
    "    for col1, col2 in combinations:\n",
    "       combination = train[col1] * train[col2]\n",
    "       train_combinations = train_combinations.join(combination.rename(f'{col1} x {col2}'))\n",
    "    \n",
    "    # ? returning features from train_combinations with correlations greater than the mean of the original\n",
    "\n",
    "    # corr_combinations = train_combinations.corr()\n",
    "    # abs_values = abs(corr_combinations['class'])\n",
    "    # new_cols = abs_values.loc[abs_values > threshold].index.tolist()\n",
    "    # if 'class' in new_cols:\n",
    "    #     new_cols.remove('class')\n",
    "    new_cols = ['habitat x cap-diameter']\n",
    "    \n",
    "    \n",
    "    train['class'] = ord_enc.inverse_transform(train['class'])\n",
    "    return train.join(train_combinations[new_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_test_combinations(test, cat_cols, num_cols, train_columns):\n",
    "    \n",
    "\n",
    "    all_columns = cat_cols + num_cols\n",
    "\n",
    "    filtered_cols = [col for col in all_columns if col != 'class']\n",
    "    print(filtered_cols)\n",
    "    combinations = itertools.combinations(filtered_cols, 2)\n",
    "\n",
    "    test_combinations = pd.DataFrame(index = test.index)\n",
    "\n",
    "    for col1, col2 in combinations:\n",
    "       combination = test[col1] * test[col2]\n",
    "       test_combinations = test_combinations.join(combination.rename(f'{col1} x {col2}'))\n",
    "    \n",
    "    # ? Remove 'class' feature from test set\n",
    "    train_columns = train_columns.drop('class')\n",
    "\n",
    "    test = test.join(test_combinations)\n",
    "\n",
    "    return test[train_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "\n",
    "    # df['stem-area'] = df['stem-height'] * df['stem-width']\n",
    "\n",
    "    # df['cap-shape-surface'] = df['cap-shape'] + df['cap-surface']\n",
    "\n",
    "    df['cap-diameter-shape'] = df.groupby(['cap-shape'])['cap-diameter'].transform('mean')\n",
    "    df['stem-root-height'] = df.groupby(['stem-root'])['stem-height'].transform('mean')\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(df):\n",
    "    cat_cols = [col for col in df.select_dtypes('object').columns if col != 'class']\n",
    "    num_cols = [col for col in df.select_dtypes('number').columns]\n",
    "    print(f'Categorical columns:\\n {cat_cols}\\n')\n",
    "    print(f'Numeric columns:\\n {num_cols}')\n",
    "\n",
    "    return cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def mutual_information(X, y):\n",
    "\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name = \"MI Scores\", index = X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending = False)\n",
    "    smoothing['mutual information'] = mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(variable):\n",
    "\n",
    "    train = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    train = train.drop('id', axis = 1)\n",
    "    test = test.drop('id', axis = 1)\n",
    "\n",
    "    y = train['class']\n",
    "    X = train.drop('class', axis = 1)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "    smoothing['X_train before'] = X_train\n",
    "\n",
    "    \n",
    "    cat_cols, num_cols = get_cols(train)\n",
    "\n",
    "    X_train = replace_non_alpha_with_nan(X_train, cat_cols)\n",
    "    X_test = replace_non_alpha_with_nan(X_test, cat_cols)\n",
    "    test = replace_non_alpha_with_nan(test, cat_cols)\n",
    "    \n",
    "    smoothing['X_train'] = X_train\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "\n",
    "    X_train = aggregate(X_train)\n",
    "    X_test = aggregate(X_test)\n",
    "    test = aggregate(test)\n",
    "\n",
    "    cat_cols, num_cols = get_cols(X_train)\n",
    "\n",
    "    print(f\"X_train columns  {X_train.columns}\")\n",
    "\n",
    "\n",
    "    X_train, X_test, test = encode_train_and_test_data(X_train, y_train, X_test,  test, num_cols, cat_cols, variable)\n",
    "    # smoothing['Series'] = X_train['cat__cap-shape_nan']\n",
    "    \n",
    "    smoothing['X_train after encoding'] = X_train\n",
    "\n",
    "    # train = find_train_combinations(train, cat_cols, num_cols) # ! Change train_new back to train after testing\n",
    "    # test = find_test_combinations(test, cat_cols, num_cols, train.columns)\n",
    "\n",
    "    def handle_missing_data(df_transformed):\n",
    "        \n",
    "        df_transformed = df_transformed.fillna(-10)\n",
    "\n",
    "        print(\"Missing values after imputation:\")\n",
    "        print(df_transformed.isnull().sum())\n",
    "        return df_transformed\n",
    "    \n",
    "    X_train = handle_missing_data(X_train)\n",
    "    X_test = handle_missing_data(X_test)\n",
    "    test = handle_missing_data(test)\n",
    "\n",
    "    # mutual_information(X_train, y_train)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "    def mcc_metric(y_pred, dmatrix):\n",
    "        y_true = dmatrix.get_label()\n",
    "        y_pred = (y_pred > 0.5).astype(int) \n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        return 'mcc', mcc\n",
    "\n",
    "    model = XGBClassifier(\n",
    "\n",
    "        colsample_bytree = 0.6,\n",
    "        max_depth = 14,\n",
    "        min_child_weight = 7,\n",
    "        random_state = 42,\n",
    "        n_estimators = 200,\n",
    "    )\n",
    "    XGB = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_test, y_test)],\n",
    "        eval_metric = mcc_metric # * Only Visual does not affect model training\n",
    "        )\n",
    "    \n",
    "    y_pred = XGB.predict(X_test)\n",
    "    score = matthews_corrcoef(y_test, y_pred)\n",
    "    print('MCC', score)\n",
    "    smoothing[variable] = score\n",
    "\n",
    "\n",
    "    test_pred_prob = XGB.predict(test)\n",
    "    test_pred_class = le.inverse_transform(test_pred_prob)\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    submission['class'] = test_pred_class\n",
    "    submission.to_csv('version_9_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "        5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,10,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:\n",
      " ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season']\n",
      "\n",
      "Numeric columns:\n",
      " ['cap-diameter', 'stem-height', 'stem-width']\n",
      "Categorical columns:\n",
      " ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season']\n",
      "\n",
      "Numeric columns:\n",
      " ['cap-diameter', 'stem-height', 'stem-width', 'cap-diameter-shape']\n",
      "X_train columns  Index(['cap-diameter', 'cap-shape', 'cap-surface', 'cap-color',\n",
      "       'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
      "       'stem-height', 'stem-width', 'stem-root', 'stem-surface', 'stem-color',\n",
      "       'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color',\n",
      "       'habitat', 'season', 'cap-diameter-shape'],\n",
      "      dtype='object')\n",
      "All Columns ['num__cap-diameter' 'num__stem-height' 'num__stem-width'\n",
      " 'num__cap-diameter-shape' 'cat__cap-shape_b' 'cat__cap-shape_c'\n",
      " 'cat__cap-shape_f' 'cat__cap-shape_o' 'cat__cap-shape_p'\n",
      " 'cat__cap-shape_s' 'cat__cap-shape_x' 'cat__cap-shape_nan'\n",
      " 'cat__cap-surface_d' 'cat__cap-surface_e' 'cat__cap-surface_g'\n",
      " 'cat__cap-surface_h' 'cat__cap-surface_i' 'cat__cap-surface_k'\n",
      " 'cat__cap-surface_l' 'cat__cap-surface_s' 'cat__cap-surface_t'\n",
      " 'cat__cap-surface_w' 'cat__cap-surface_y' 'cat__cap-surface_nan'\n",
      " 'cat__cap-color_b' 'cat__cap-color_e' 'cat__cap-color_g'\n",
      " 'cat__cap-color_k' 'cat__cap-color_l' 'cat__cap-color_n'\n",
      " 'cat__cap-color_o' 'cat__cap-color_p' 'cat__cap-color_r'\n",
      " 'cat__cap-color_u' 'cat__cap-color_w' 'cat__cap-color_y'\n",
      " 'cat__cap-color_nan' 'cat__does-bruise-or-bleed_f'\n",
      " 'cat__does-bruise-or-bleed_t' 'cat__does-bruise-or-bleed_nan'\n",
      " 'cat__gill-attachment_a' 'cat__gill-attachment_d'\n",
      " 'cat__gill-attachment_e' 'cat__gill-attachment_f'\n",
      " 'cat__gill-attachment_p' 'cat__gill-attachment_s'\n",
      " 'cat__gill-attachment_x' 'cat__gill-attachment_nan' 'cat__gill-spacing_c'\n",
      " 'cat__gill-spacing_d' 'cat__gill-spacing_f' 'cat__gill-spacing_nan'\n",
      " 'cat__gill-color_b' 'cat__gill-color_e' 'cat__gill-color_f'\n",
      " 'cat__gill-color_g' 'cat__gill-color_k' 'cat__gill-color_n'\n",
      " 'cat__gill-color_o' 'cat__gill-color_p' 'cat__gill-color_r'\n",
      " 'cat__gill-color_u' 'cat__gill-color_w' 'cat__gill-color_y'\n",
      " 'cat__gill-color_nan' 'cat__stem-root_b' 'cat__stem-root_c'\n",
      " 'cat__stem-root_f' 'cat__stem-root_r' 'cat__stem-root_s'\n",
      " 'cat__stem-root_nan' 'cat__stem-surface_f' 'cat__stem-surface_g'\n",
      " 'cat__stem-surface_h' 'cat__stem-surface_i' 'cat__stem-surface_k'\n",
      " 'cat__stem-surface_s' 'cat__stem-surface_t' 'cat__stem-surface_y'\n",
      " 'cat__stem-surface_nan' 'cat__stem-color_b' 'cat__stem-color_e'\n",
      " 'cat__stem-color_f' 'cat__stem-color_g' 'cat__stem-color_k'\n",
      " 'cat__stem-color_l' 'cat__stem-color_n' 'cat__stem-color_o'\n",
      " 'cat__stem-color_p' 'cat__stem-color_r' 'cat__stem-color_u'\n",
      " 'cat__stem-color_w' 'cat__stem-color_y' 'cat__stem-color_nan'\n",
      " 'cat__veil-type_u' 'cat__veil-type_nan' 'cat__veil-color_e'\n",
      " 'cat__veil-color_k' 'cat__veil-color_n' 'cat__veil-color_u'\n",
      " 'cat__veil-color_w' 'cat__veil-color_y' 'cat__veil-color_nan'\n",
      " 'cat__has-ring_f' 'cat__has-ring_t' 'cat__has-ring_nan'\n",
      " 'cat__ring-type_e' 'cat__ring-type_f' 'cat__ring-type_g'\n",
      " 'cat__ring-type_l' 'cat__ring-type_m' 'cat__ring-type_p'\n",
      " 'cat__ring-type_r' 'cat__ring-type_z' 'cat__ring-type_nan'\n",
      " 'cat__spore-print-color_g' 'cat__spore-print-color_k'\n",
      " 'cat__spore-print-color_n' 'cat__spore-print-color_p'\n",
      " 'cat__spore-print-color_r' 'cat__spore-print-color_u'\n",
      " 'cat__spore-print-color_w' 'cat__spore-print-color_nan' 'cat__habitat_d'\n",
      " 'cat__habitat_g' 'cat__habitat_h' 'cat__habitat_l' 'cat__habitat_m'\n",
      " 'cat__habitat_p' 'cat__habitat_u' 'cat__habitat_w' 'cat__habitat_nan'\n",
      " 'cat__season_a' 'cat__season_s' 'cat__season_u' 'cat__season_w']\n",
      "Train Transformed = [[ 2.58  2.87  5.69 ...  0.    0.    0.  ]\n",
      " [ 1.83  5.36  2.7  ...  0.    0.    0.  ]\n",
      " [ 5.22  7.32  7.41 ...  0.    0.    0.  ]\n",
      " ...\n",
      " [16.77  6.2  38.82 ...  0.    0.    0.  ]\n",
      " [ 6.29  5.35  7.71 ...  0.    0.    0.  ]\n",
      " [12.36 11.   17.48 ...  0.    0.    0.  ]]\n",
      "Missing values after imputation:\n",
      "num__cap-diameter          0\n",
      "num__stem-height           0\n",
      "num__stem-width            0\n",
      "num__cap-diameter-shape    0\n",
      "cat__cap-shape_b           0\n",
      "                          ..\n",
      "cat__habitat_nan           0\n",
      "cat__season_a              0\n",
      "cat__season_s              0\n",
      "cat__season_u              0\n",
      "cat__season_w              0\n",
      "Length: 136, dtype: int64\n",
      "Missing values after imputation:\n",
      "num__cap-diameter          0\n",
      "num__stem-height           0\n",
      "num__stem-width            0\n",
      "num__cap-diameter-shape    0\n",
      "cat__cap-shape_b           0\n",
      "                          ..\n",
      "cat__habitat_nan           0\n",
      "cat__season_a              0\n",
      "cat__season_s              0\n",
      "cat__season_u              0\n",
      "cat__season_w              0\n",
      "Length: 136, dtype: int64\n",
      "Missing values after imputation:\n",
      "num__cap-diameter          0\n",
      "num__stem-height           0\n",
      "num__stem-width            0\n",
      "num__cap-diameter-shape    0\n",
      "cat__cap-shape_b           0\n",
      "                          ..\n",
      "cat__habitat_nan           0\n",
      "cat__season_a              0\n",
      "cat__season_s              0\n",
      "cat__season_u              0\n",
      "cat__season_w              0\n",
      "Length: 136, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugph\\ML\\s4e8\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.46278\tvalidation_0-mcc:0.93474\n",
      "[1]\tvalidation_0-logloss:0.33116\tvalidation_0-mcc:0.96542\n",
      "[2]\tvalidation_0-logloss:0.24195\tvalidation_0-mcc:0.97427\n",
      "[3]\tvalidation_0-logloss:0.18825\tvalidation_0-mcc:0.97719\n",
      "[4]\tvalidation_0-logloss:0.15418\tvalidation_0-mcc:0.97782\n",
      "[5]\tvalidation_0-logloss:0.12243\tvalidation_0-mcc:0.97908\n",
      "[6]\tvalidation_0-logloss:0.10474\tvalidation_0-mcc:0.97965\n",
      "[7]\tvalidation_0-logloss:0.09019\tvalidation_0-mcc:0.97992\n",
      "[8]\tvalidation_0-logloss:0.07843\tvalidation_0-mcc:0.98040\n",
      "[9]\tvalidation_0-logloss:0.06799\tvalidation_0-mcc:0.98087\n",
      "[10]\tvalidation_0-logloss:0.06224\tvalidation_0-mcc:0.98110\n",
      "[11]\tvalidation_0-logloss:0.05635\tvalidation_0-mcc:0.98142\n",
      "[12]\tvalidation_0-logloss:0.05212\tvalidation_0-mcc:0.98166\n",
      "[13]\tvalidation_0-logloss:0.05007\tvalidation_0-mcc:0.98190\n",
      "[14]\tvalidation_0-logloss:0.04663\tvalidation_0-mcc:0.98212\n",
      "[15]\tvalidation_0-logloss:0.04540\tvalidation_0-mcc:0.98231\n",
      "[16]\tvalidation_0-logloss:0.04330\tvalidation_0-mcc:0.98262\n",
      "[17]\tvalidation_0-logloss:0.04230\tvalidation_0-mcc:0.98281\n",
      "[18]\tvalidation_0-logloss:0.04109\tvalidation_0-mcc:0.98303\n",
      "[19]\tvalidation_0-logloss:0.04036\tvalidation_0-mcc:0.98313\n",
      "[20]\tvalidation_0-logloss:0.03986\tvalidation_0-mcc:0.98316\n",
      "[21]\tvalidation_0-logloss:0.03941\tvalidation_0-mcc:0.98327\n",
      "[22]\tvalidation_0-logloss:0.03918\tvalidation_0-mcc:0.98330\n",
      "[23]\tvalidation_0-logloss:0.03891\tvalidation_0-mcc:0.98334\n",
      "[24]\tvalidation_0-logloss:0.03860\tvalidation_0-mcc:0.98345\n",
      "[25]\tvalidation_0-logloss:0.03829\tvalidation_0-mcc:0.98355\n",
      "[26]\tvalidation_0-logloss:0.03821\tvalidation_0-mcc:0.98354\n",
      "[27]\tvalidation_0-logloss:0.03800\tvalidation_0-mcc:0.98362\n",
      "[28]\tvalidation_0-logloss:0.03795\tvalidation_0-mcc:0.98367\n",
      "[29]\tvalidation_0-logloss:0.03781\tvalidation_0-mcc:0.98374\n",
      "[30]\tvalidation_0-logloss:0.03770\tvalidation_0-mcc:0.98377\n",
      "[31]\tvalidation_0-logloss:0.03767\tvalidation_0-mcc:0.98378\n",
      "[32]\tvalidation_0-logloss:0.03759\tvalidation_0-mcc:0.98377\n",
      "[33]\tvalidation_0-logloss:0.03754\tvalidation_0-mcc:0.98381\n",
      "[34]\tvalidation_0-logloss:0.03747\tvalidation_0-mcc:0.98389\n",
      "[35]\tvalidation_0-logloss:0.03739\tvalidation_0-mcc:0.98391\n",
      "[36]\tvalidation_0-logloss:0.03733\tvalidation_0-mcc:0.98393\n",
      "[37]\tvalidation_0-logloss:0.03732\tvalidation_0-mcc:0.98394\n",
      "[38]\tvalidation_0-logloss:0.03730\tvalidation_0-mcc:0.98397\n",
      "[39]\tvalidation_0-logloss:0.03729\tvalidation_0-mcc:0.98396\n",
      "[40]\tvalidation_0-logloss:0.03728\tvalidation_0-mcc:0.98396\n",
      "[41]\tvalidation_0-logloss:0.03727\tvalidation_0-mcc:0.98397\n",
      "[42]\tvalidation_0-logloss:0.03723\tvalidation_0-mcc:0.98400\n",
      "[43]\tvalidation_0-logloss:0.03722\tvalidation_0-mcc:0.98401\n",
      "[44]\tvalidation_0-logloss:0.03721\tvalidation_0-mcc:0.98401\n",
      "[45]\tvalidation_0-logloss:0.03721\tvalidation_0-mcc:0.98401\n",
      "[46]\tvalidation_0-logloss:0.03720\tvalidation_0-mcc:0.98404\n",
      "[47]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98402\n",
      "[48]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98405\n",
      "[49]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98404\n",
      "[50]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98407\n",
      "[51]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98408\n",
      "[52]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98407\n",
      "[53]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98409\n",
      "[54]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98410\n",
      "[55]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98411\n",
      "[56]\tvalidation_0-logloss:0.03716\tvalidation_0-mcc:0.98414\n",
      "[57]\tvalidation_0-logloss:0.03717\tvalidation_0-mcc:0.98411\n",
      "[58]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98414\n",
      "[59]\tvalidation_0-logloss:0.03720\tvalidation_0-mcc:0.98412\n",
      "[60]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98414\n",
      "[61]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98415\n",
      "[62]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98417\n",
      "[63]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98418\n",
      "[64]\tvalidation_0-logloss:0.03719\tvalidation_0-mcc:0.98418\n",
      "[65]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98418\n",
      "[66]\tvalidation_0-logloss:0.03718\tvalidation_0-mcc:0.98419\n",
      "[67]\tvalidation_0-logloss:0.03717\tvalidation_0-mcc:0.98419\n",
      "[68]\tvalidation_0-logloss:0.03717\tvalidation_0-mcc:0.98425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m smoothing \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# for i in np.linspace(5,20,4):\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     model(i)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# model()\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[71], line 81\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(variable)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcc\u001b[39m\u001b[38;5;124m'\u001b[39m, mcc\n\u001b[0;32m     73\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m     colsample_bytree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m     80\u001b[0m )\n\u001b[1;32m---> 81\u001b[0m XGB \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmcc_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# * Only Visual does not affect model training\u001b[39;49;00m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m XGB\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     89\u001b[0m score \u001b[38;5;241m=\u001b[39m matthews_corrcoef(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\hugph\\ML\\s4e8\\venv\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hugph\\ML\\s4e8\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hugph\\ML\\s4e8\\venv\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hugph\\ML\\s4e8\\venv\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugph\\ML\\s4e8\\venv\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "smoothing = {}\n",
    "\n",
    "# for i in np.linspace(5,20,4):\n",
    "#     model(i)\n",
    "# model()\n",
    "model(9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * One Hot Encoding\n",
    "# * 0.9840663425977435\n",
    "# * with stem-area MCC 0.9839074927182325\n",
    "# * with stem-area + cap-surface-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ? Notes\n",
    "# No different between fit_transform and transform for test data in preprocessing but transform probably recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mutual information'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msmoothing\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmutual information\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutual information\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mutual information'"
     ]
    }
   ],
   "source": [
    "# smoothing['mutual information'].reset_index().to_csv('mutual information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
