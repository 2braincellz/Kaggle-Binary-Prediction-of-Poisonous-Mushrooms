{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from xgboost import XGBClassifier\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_non_alpha_with_nan(df, categories):\n",
    "    # cols_to_filter = ['cap-shape', 'cap-surface', 'cap-color', \n",
    "    #                   'does-bruise-or-bleed', 'gill-attachment', \n",
    "    #                   'gill-spacing', 'gill-color', 'stem-surface', \n",
    "    #                   'stem-color', 'has-ring', 'ring-type', 'habitat', 'stem-root', 'veil-type', 'veil-color', 'spore-print-color']\n",
    "\n",
    "    cols_to_filter = categories\n",
    "    \n",
    "\n",
    "    alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', \n",
    "                     'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    # col_values = {}\n",
    "    # for col in cols_to_filter:\n",
    "    #     value_counts = train[col].value_counts()# ? ONLY Based on trained dataset\n",
    "    #     col_values[col] = value_counts[value_counts > 10].index.values.tolist()\n",
    "\n",
    "\n",
    "    # def filter_alpha(value, value_list_no_outliers):\n",
    "    #     if isinstance(value, str):\n",
    "    #         return value if len(value) == 1 and value in value_list_no_outliers and value in alphabet_list else np.nan # if value is a single character\n",
    "        \n",
    "    #     return np.nan\n",
    "    \n",
    "    # for col in cols_to_filter:\n",
    "    #     df[col] = df[col].apply(lambda x : filter_alpha(x, col_values[col]))\n",
    "\n",
    "\n",
    "    # * Customized feature engineering\n",
    "    features_dict = {\n",
    "        'cap_shape': ['x', 'f', 's', 'b', 'o', 'p', 'c'],\n",
    "        'cap_surface': ['t', 's', 'y', 'h', 'g', 'd', 'k', 'e', 'i', 'w', 'l'],\n",
    "        'cap_color': ['n', 'y', 'w', 'g', 'e', 'o', 'p', 'r', 'u', 'b', 'k', 'l'],\n",
    "        'does_bruise_or_bleed': ['f', 't'],\n",
    "        'gill_attachment': ['a', 'd', 'x', 'e', 's', 'p', 'f'],\n",
    "        'gill_spacing': ['c', 'd', 'f'],\n",
    "        'gill_color': ['w', 'n', 'y', 'p', 'g', 'o', 'k', 'f', 'r', 'e', 'b', 'u'],\n",
    "        'stem_root': ['b', 's', 'r', 'c', 'f'],\n",
    "        'stem_surface': ['s', 'y', 'i', 't', 'g', 'k', 'h', 'f'],\n",
    "        'stem_color': ['w', 'n', 'y', 'g', 'o', 'e', 'u', 'p', 'k', 'r', 'l', 'b', 'f'],\n",
    "        'veil_type': ['u'],\n",
    "        'veil_color': ['w', 'y', 'n', 'u', 'k', 'e'],\n",
    "        'has_ring': ['f', 't'],\n",
    "        'ring_type': ['f', 'e', 'z', 'l', 'r', 'p', 'g', 'm'],\n",
    "        'spore_print_color': ['k', 'p', 'w', 'n', 'r', 'u', 'g'],\n",
    "        'habitat': ['d', 'g', 'l', 'm', 'h', 'w', 'p', 'u'],\n",
    "        'season': ['a', 'u', 'w', 's']\n",
    "    }\n",
    "\n",
    "\n",
    "    for classes, cols  in zip(features_dict.keys(), cols_to_filter):\n",
    "        # df.loc[(~df[cols].isin(features_dict[classes])) & pd.notna(df[cols]), cols] = 'missing'\n",
    "        df.loc[~df[cols].isin(features_dict[classes]), cols] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_train_and_test_data(df_train, target, df_test, df_validation, kaggle_test, num_cols, cat_cols, variable):\n",
    "\n",
    "    numeric_transformer = Pipeline(steps = [\n",
    "        ('imputer', KNNImputer(n_neighbors = 3))\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps = [\n",
    "        # ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "        # ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        # ('Target', TargetEncoder(smoothing=variable)),\n",
    "        ('OneHot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "\n",
    "        # ('adjust', FunctionTransformer(lambda x : x + 1)) # * Adjust function\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', numeric_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)\n",
    "        ],\n",
    "        remainder = 'passthrough'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # * Target Encoding\n",
    "    # train_te = preprocessor.fit_transform(df_train[all_columns], target)\n",
    "    # test_te = preprocessor.transform(df_test[all_columns])\n",
    "    # val_te = preprocessor.transform(df_validation[all_columns])\n",
    "\n",
    "    all_columns = num_cols + cat_cols\n",
    "\n",
    "    train_te = preprocessor.fit_transform(df_train[all_columns])\n",
    "    test_te = preprocessor.transform(df_test[all_columns])\n",
    "    val_te = preprocessor.transform(df_validation[all_columns])\n",
    "\n",
    "\n",
    "    feature_names_out = preprocessor.get_feature_names_out()\n",
    "\n",
    "    smoothing['feature names'] = feature_names_out\n",
    "\n",
    "\n",
    "    print(f\"All Columns {feature_names_out}\")\n",
    "\n",
    "    print(f\"Train Transformed = {train_te}\")\n",
    "\n",
    "    # smoothing['categories'] = \n",
    "\n",
    "    df_train_transformed = pd.DataFrame(train_te, columns = feature_names_out)\n",
    "    df_test_transformed = pd.DataFrame(test_te, columns = feature_names_out)\n",
    "    df_validation_transformed = pd.DataFrame(val_te, columns = feature_names_out)\n",
    "\n",
    "    # print(preprocessor['cat'].get_feature_names_out())\n",
    "\n",
    "    # df_transformed = pd.DataFrame(preprocessor.fit_transform(df[num_cols + cat_cols], df['class']), columns = num_cols + cat_cols)\n",
    "\n",
    "    df_train_final = df_train_transformed\n",
    "    df_test_final = df_test_transformed\n",
    "    df_validation_final = df_validation_transformed\n",
    "\n",
    "\n",
    "    kaggle_test_te = preprocessor.transform(kaggle_test[all_columns])\n",
    "    kaggle_test_final = pd.DataFrame(kaggle_test_te, columns = feature_names_out)\n",
    "\n",
    "\n",
    "    return df_train_final, df_test_final, df_validation_final, kaggle_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def find_train_combinations(train, cat_cols, num_cols):\n",
    "    \n",
    "    \n",
    "    all_columns = cat_cols + num_cols\n",
    "\n",
    "    # ? returning features from train_combinations with correlations greater than the mean of the original\n",
    "    \n",
    "    ord_enc = LabelEncoder()\n",
    "    train['class'] = ord_enc.fit_transform(train['class'])\n",
    "\n",
    "    corr_matrix = train.corr()\n",
    "    \n",
    "    threshold = abs(corr_matrix['class']).sort_values(ascending=False).mean()\n",
    "    print(f\" Mean Correlation of Original Data {threshold}\")\n",
    "\n",
    "\n",
    "    filtered_cols = [col for col in all_columns if col != 'class']\n",
    "    print(filtered_cols)\n",
    "    print(train.columns)\n",
    "    combinations = itertools.combinations(filtered_cols, 2)\n",
    "    print(combinations)\n",
    "\n",
    "    train_combinations = train['class'].to_frame()\n",
    "\n",
    "    for col1, col2 in combinations:\n",
    "       combination = train[col1] * train[col2]\n",
    "       train_combinations = train_combinations.join(combination.rename(f'{col1} x {col2}'))\n",
    "    \n",
    "    # ? returning features from train_combinations with correlations greater than the mean of the original\n",
    "\n",
    "    # corr_combinations = train_combinations.corr()\n",
    "    # abs_values = abs(corr_combinations['class'])\n",
    "    # new_cols = abs_values.loc[abs_values > threshold].index.tolist()\n",
    "    # if 'class' in new_cols:\n",
    "    #     new_cols.remove('class')\n",
    "    new_cols = ['habitat x cap-diameter']\n",
    "    \n",
    "    \n",
    "    train['class'] = ord_enc.inverse_transform(train['class'])\n",
    "    return train.join(train_combinations[new_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_test_combinations(test, cat_cols, num_cols, train_columns):\n",
    "    \n",
    "\n",
    "    all_columns = cat_cols + num_cols\n",
    "\n",
    "    filtered_cols = [col for col in all_columns if col != 'class']\n",
    "    print(filtered_cols)\n",
    "    combinations = itertools.combinations(filtered_cols, 2)\n",
    "\n",
    "    test_combinations = pd.DataFrame(index = test.index)\n",
    "\n",
    "    for col1, col2 in combinations:\n",
    "       combination = test[col1] * test[col2]\n",
    "       test_combinations = test_combinations.join(combination.rename(f'{col1} x {col2}'))\n",
    "    \n",
    "    # ? Remove 'class' feature from test set\n",
    "    train_columns = train_columns.drop('class')\n",
    "\n",
    "    test = test.join(test_combinations)\n",
    "\n",
    "    return test[train_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "\n",
    "\n",
    "    merging = df.groupby(['cap-shape'])['cap-diameter'].median().reset_index()\n",
    "\n",
    "    names = {\"cap-diameter\" : \"cap-shape x cap-diameter median\"}\n",
    "\n",
    "    merging = merging.rename(columns = names)\n",
    "\n",
    "\n",
    "    return pd.merge(df, merging, on = \"cap-shape\", how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(variable):\n",
    "\n",
    "    train = pd.read_csv('train.csv')\n",
    "    # secondary_data = pd.read_csv('secondary_data.csv', sep = ';')\n",
    "\n",
    "\n",
    "    # train = pd.concat([train, secondary_data], ignore_index = True)\n",
    "    test = pd.read_csv('test.csv')\n",
    "    train = train.drop('id', axis = 1)\n",
    "    test = test.drop('id', axis = 1)\n",
    "\n",
    "    y = train['class']\n",
    "    X = train.drop('class', axis = 1)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "    smoothing['X_train before'] = X_train\n",
    "\n",
    "    \n",
    "    cat_cols = [col for col in train.select_dtypes('object').columns if col != 'class']\n",
    "    num_cols = [col for col in train.select_dtypes('number').columns]\n",
    "    print(f'Categorical columns:\\n {cat_cols}\\n')\n",
    "    print(f'Numeric columns:\\n {num_cols}')\n",
    "\n",
    "    X_train = replace_non_alpha_with_nan(X_train, cat_cols)\n",
    "    X_test = replace_non_alpha_with_nan(X_test, cat_cols)\n",
    "    X_val = replace_non_alpha_with_nan(X_val, cat_cols)\n",
    "    test = replace_non_alpha_with_nan(test, cat_cols)\n",
    "    \n",
    "    smoothing['X_train'] = X_train\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    y_val = le.transform(y_val)\n",
    "\n",
    "    # X_train = aggregate(X_train)\n",
    "    # X_test = aggregate(X_test)\n",
    "    # X_val = aggregate(X_val)\n",
    "    # test = aggregate(test)\n",
    "\n",
    "    print(f\"X_train columns  {X_train.columns}\")\n",
    "\n",
    "\n",
    "    X_train, X_test, X_val, test = encode_train_and_test_data(X_train, y_train, X_test, X_val, test, num_cols, cat_cols, variable)\n",
    "\n",
    "    # smoothing['Series'] = X_train['cat__cap-shape_nan']\n",
    "    \n",
    "    smoothing['X_train after encoding'] = X_train\n",
    "\n",
    "    # train = find_train_combinations(train, cat_cols, num_cols) # ! Change train_new back to train after testing\n",
    "    # test = find_test_combinations(test, cat_cols, num_cols, train.columns)\n",
    "\n",
    "    def handle_missing_data(df_transformed):\n",
    "        \n",
    "        df_transformed = df_transformed.fillna(-10)\n",
    "\n",
    "        print(\"Missing values after imputation:\")\n",
    "        print(df_transformed.isnull().sum())\n",
    "        return df_transformed\n",
    "    \n",
    "    X_train = handle_missing_data(X_train)\n",
    "    X_test = handle_missing_data(X_test)\n",
    "    X_val = handle_missing_data(X_val)\n",
    "    test = handle_missing_data(test)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "    def mcc_metric(y_pred, dmatrix):\n",
    "        y_true = dmatrix.get_label()\n",
    "        y_pred = (y_pred > 0.5).astype(int) \n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        return 'mcc', mcc\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        device = 'cuda',\n",
    "        colsample_bytree = 0.6,\n",
    "        max_depth = 14,\n",
    "        min_child_weight = 7,\n",
    "        random_state = 42,\n",
    "        n_estimators = 200,\n",
    "    )\n",
    "    XGB = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_test, y_test)],\n",
    "        eval_metric = mcc_metric # * Only Visual does not affect model training\n",
    "        )\n",
    "    \n",
    "    y_pred = XGB.predict(X_val)\n",
    "    score = matthews_corrcoef(y_val, y_pred)\n",
    "    print('MCC', score)\n",
    "    smoothing[variable] = score\n",
    "\n",
    "    print(test.info())\n",
    "\n",
    "    test_pred_prob = XGB.predict(test)\n",
    "    test_pred_class = le.inverse_transform(test_pred_prob)\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    submission['class'] = test_pred_class\n",
    "    submission.to_csv('version_9_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:\n",
      " ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season']\n",
      "\n",
      "Numeric columns:\n",
      " ['cap-diameter', 'stem-height', 'stem-width']\n",
      "X_train columns  Index(['cap-diameter', 'cap-shape', 'cap-surface', 'cap-color',\n",
      "       'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
      "       'stem-height', 'stem-width', 'stem-root', 'stem-surface', 'stem-color',\n",
      "       'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color',\n",
      "       'habitat', 'season'],\n",
      "      dtype='object')\n",
      "All Columns ['num__cap-diameter' 'num__stem-height' 'num__stem-width'\n",
      " 'cat__cap-shape_b' 'cat__cap-shape_c' 'cat__cap-shape_f'\n",
      " 'cat__cap-shape_o' 'cat__cap-shape_p' 'cat__cap-shape_s'\n",
      " 'cat__cap-shape_x' 'cat__cap-shape_nan' 'cat__cap-surface_d'\n",
      " 'cat__cap-surface_e' 'cat__cap-surface_g' 'cat__cap-surface_h'\n",
      " 'cat__cap-surface_i' 'cat__cap-surface_k' 'cat__cap-surface_l'\n",
      " 'cat__cap-surface_s' 'cat__cap-surface_t' 'cat__cap-surface_w'\n",
      " 'cat__cap-surface_y' 'cat__cap-surface_nan' 'cat__cap-color_b'\n",
      " 'cat__cap-color_e' 'cat__cap-color_g' 'cat__cap-color_k'\n",
      " 'cat__cap-color_l' 'cat__cap-color_n' 'cat__cap-color_o'\n",
      " 'cat__cap-color_p' 'cat__cap-color_r' 'cat__cap-color_u'\n",
      " 'cat__cap-color_w' 'cat__cap-color_y' 'cat__cap-color_nan'\n",
      " 'cat__does-bruise-or-bleed_f' 'cat__does-bruise-or-bleed_t'\n",
      " 'cat__does-bruise-or-bleed_nan' 'cat__gill-attachment_a'\n",
      " 'cat__gill-attachment_d' 'cat__gill-attachment_e'\n",
      " 'cat__gill-attachment_f' 'cat__gill-attachment_p'\n",
      " 'cat__gill-attachment_s' 'cat__gill-attachment_x'\n",
      " 'cat__gill-attachment_nan' 'cat__gill-spacing_c' 'cat__gill-spacing_d'\n",
      " 'cat__gill-spacing_f' 'cat__gill-spacing_nan' 'cat__gill-color_b'\n",
      " 'cat__gill-color_e' 'cat__gill-color_f' 'cat__gill-color_g'\n",
      " 'cat__gill-color_k' 'cat__gill-color_n' 'cat__gill-color_o'\n",
      " 'cat__gill-color_p' 'cat__gill-color_r' 'cat__gill-color_u'\n",
      " 'cat__gill-color_w' 'cat__gill-color_y' 'cat__gill-color_nan'\n",
      " 'cat__stem-root_b' 'cat__stem-root_c' 'cat__stem-root_f'\n",
      " 'cat__stem-root_r' 'cat__stem-root_s' 'cat__stem-root_nan'\n",
      " 'cat__stem-surface_f' 'cat__stem-surface_g' 'cat__stem-surface_h'\n",
      " 'cat__stem-surface_i' 'cat__stem-surface_k' 'cat__stem-surface_s'\n",
      " 'cat__stem-surface_t' 'cat__stem-surface_y' 'cat__stem-surface_nan'\n",
      " 'cat__stem-color_b' 'cat__stem-color_e' 'cat__stem-color_f'\n",
      " 'cat__stem-color_g' 'cat__stem-color_k' 'cat__stem-color_l'\n",
      " 'cat__stem-color_n' 'cat__stem-color_o' 'cat__stem-color_p'\n",
      " 'cat__stem-color_r' 'cat__stem-color_u' 'cat__stem-color_w'\n",
      " 'cat__stem-color_y' 'cat__stem-color_nan' 'cat__veil-type_u'\n",
      " 'cat__veil-type_nan' 'cat__veil-color_e' 'cat__veil-color_k'\n",
      " 'cat__veil-color_n' 'cat__veil-color_u' 'cat__veil-color_w'\n",
      " 'cat__veil-color_y' 'cat__veil-color_nan' 'cat__has-ring_f'\n",
      " 'cat__has-ring_t' 'cat__has-ring_nan' 'cat__ring-type_e'\n",
      " 'cat__ring-type_f' 'cat__ring-type_g' 'cat__ring-type_l'\n",
      " 'cat__ring-type_m' 'cat__ring-type_p' 'cat__ring-type_r'\n",
      " 'cat__ring-type_z' 'cat__ring-type_nan' 'cat__spore-print-color_g'\n",
      " 'cat__spore-print-color_k' 'cat__spore-print-color_n'\n",
      " 'cat__spore-print-color_p' 'cat__spore-print-color_r'\n",
      " 'cat__spore-print-color_u' 'cat__spore-print-color_w'\n",
      " 'cat__spore-print-color_nan' 'cat__habitat_d' 'cat__habitat_g'\n",
      " 'cat__habitat_h' 'cat__habitat_l' 'cat__habitat_m' 'cat__habitat_p'\n",
      " 'cat__habitat_u' 'cat__habitat_w' 'cat__habitat_nan' 'cat__season_a'\n",
      " 'cat__season_s' 'cat__season_u' 'cat__season_w']\n",
      "Train Transformed = [[ 2.58  2.87  5.69 ...  0.    0.    0.  ]\n",
      " [ 1.83  5.36  2.7  ...  0.    0.    0.  ]\n",
      " [ 5.22  7.32  7.41 ...  0.    0.    0.  ]\n",
      " ...\n",
      " [16.77  6.2  38.82 ...  0.    0.    0.  ]\n",
      " [ 6.29  5.35  7.71 ...  0.    0.    0.  ]\n",
      " [12.36 11.   17.48 ...  0.    0.    0.  ]]\n",
      "Missing values after imputation:\n",
      "num__cap-diameter    0\n",
      "num__stem-height     0\n",
      "num__stem-width      0\n",
      "cat__cap-shape_b     0\n",
      "cat__cap-shape_c     0\n",
      "                    ..\n",
      "cat__habitat_nan     0\n",
      "cat__season_a        0\n",
      "cat__season_s        0\n",
      "cat__season_u        0\n",
      "cat__season_w        0\n",
      "Length: 135, dtype: int64\n",
      "Missing values after imputation:\n",
      "num__cap-diameter    0\n",
      "num__stem-height     0\n",
      "num__stem-width      0\n",
      "cat__cap-shape_b     0\n",
      "cat__cap-shape_c     0\n",
      "                    ..\n",
      "cat__habitat_nan     0\n",
      "cat__season_a        0\n",
      "cat__season_s        0\n",
      "cat__season_u        0\n",
      "cat__season_w        0\n",
      "Length: 135, dtype: int64\n",
      "Missing values after imputation:\n",
      "num__cap-diameter    0\n",
      "num__stem-height     0\n",
      "num__stem-width      0\n",
      "cat__cap-shape_b     0\n",
      "cat__cap-shape_c     0\n",
      "                    ..\n",
      "cat__habitat_nan     0\n",
      "cat__season_a        0\n",
      "cat__season_s        0\n",
      "cat__season_u        0\n",
      "cat__season_w        0\n",
      "Length: 135, dtype: int64\n",
      "Missing values after imputation:\n",
      "num__cap-diameter    0\n",
      "num__stem-height     0\n",
      "num__stem-width      0\n",
      "cat__cap-shape_b     0\n",
      "cat__cap-shape_c     0\n",
      "                    ..\n",
      "cat__habitat_nan     0\n",
      "cat__season_a        0\n",
      "cat__season_s        0\n",
      "cat__season_u        0\n",
      "cat__season_w        0\n",
      "Length: 135, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugph\\Ml\\s4e8\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.47682\tvalidation_0-mcc:0.89619\n",
      "[1]\tvalidation_0-logloss:0.33956\tvalidation_0-mcc:0.96131\n",
      "[2]\tvalidation_0-logloss:0.28013\tvalidation_0-mcc:0.96287\n",
      "[3]\tvalidation_0-logloss:0.22134\tvalidation_0-mcc:0.96903\n",
      "[4]\tvalidation_0-logloss:0.16872\tvalidation_0-mcc:0.97399\n",
      "[5]\tvalidation_0-logloss:0.13979\tvalidation_0-mcc:0.97618\n",
      "[6]\tvalidation_0-logloss:0.11106\tvalidation_0-mcc:0.97829\n",
      "[7]\tvalidation_0-logloss:0.09386\tvalidation_0-mcc:0.97930\n",
      "[8]\tvalidation_0-logloss:0.07996\tvalidation_0-mcc:0.98013\n",
      "[9]\tvalidation_0-logloss:0.07107\tvalidation_0-mcc:0.98056\n",
      "[10]\tvalidation_0-logloss:0.06334\tvalidation_0-mcc:0.98088\n",
      "[11]\tvalidation_0-logloss:0.05820\tvalidation_0-mcc:0.98119\n",
      "[12]\tvalidation_0-logloss:0.05475\tvalidation_0-mcc:0.98137\n",
      "[13]\tvalidation_0-logloss:0.05180\tvalidation_0-mcc:0.98157\n",
      "[14]\tvalidation_0-logloss:0.04851\tvalidation_0-mcc:0.98198\n",
      "[15]\tvalidation_0-logloss:0.04647\tvalidation_0-mcc:0.98216\n",
      "[16]\tvalidation_0-logloss:0.04498\tvalidation_0-mcc:0.98223\n",
      "[17]\tvalidation_0-logloss:0.04341\tvalidation_0-mcc:0.98245\n",
      "[18]\tvalidation_0-logloss:0.04287\tvalidation_0-mcc:0.98250\n",
      "[19]\tvalidation_0-logloss:0.04179\tvalidation_0-mcc:0.98258\n",
      "[20]\tvalidation_0-logloss:0.04071\tvalidation_0-mcc:0.98290\n",
      "[21]\tvalidation_0-logloss:0.03998\tvalidation_0-mcc:0.98309\n",
      "[22]\tvalidation_0-logloss:0.03973\tvalidation_0-mcc:0.98310\n",
      "[23]\tvalidation_0-logloss:0.03941\tvalidation_0-mcc:0.98310\n",
      "[24]\tvalidation_0-logloss:0.03900\tvalidation_0-mcc:0.98323\n",
      "[25]\tvalidation_0-logloss:0.03862\tvalidation_0-mcc:0.98326\n",
      "[26]\tvalidation_0-logloss:0.03844\tvalidation_0-mcc:0.98336\n",
      "[27]\tvalidation_0-logloss:0.03839\tvalidation_0-mcc:0.98340\n",
      "[28]\tvalidation_0-logloss:0.03827\tvalidation_0-mcc:0.98340\n",
      "[29]\tvalidation_0-logloss:0.03816\tvalidation_0-mcc:0.98347\n",
      "[30]\tvalidation_0-logloss:0.03803\tvalidation_0-mcc:0.98349\n",
      "[31]\tvalidation_0-logloss:0.03789\tvalidation_0-mcc:0.98349\n",
      "[32]\tvalidation_0-logloss:0.03786\tvalidation_0-mcc:0.98353\n",
      "[33]\tvalidation_0-logloss:0.03776\tvalidation_0-mcc:0.98356\n",
      "[34]\tvalidation_0-logloss:0.03771\tvalidation_0-mcc:0.98353\n",
      "[35]\tvalidation_0-logloss:0.03763\tvalidation_0-mcc:0.98363\n",
      "[36]\tvalidation_0-logloss:0.03759\tvalidation_0-mcc:0.98362\n",
      "[37]\tvalidation_0-logloss:0.03756\tvalidation_0-mcc:0.98365\n",
      "[38]\tvalidation_0-logloss:0.03754\tvalidation_0-mcc:0.98363\n",
      "[39]\tvalidation_0-logloss:0.03750\tvalidation_0-mcc:0.98365\n",
      "[40]\tvalidation_0-logloss:0.03746\tvalidation_0-mcc:0.98368\n",
      "[41]\tvalidation_0-logloss:0.03746\tvalidation_0-mcc:0.98369\n",
      "[42]\tvalidation_0-logloss:0.03744\tvalidation_0-mcc:0.98378\n",
      "[43]\tvalidation_0-logloss:0.03743\tvalidation_0-mcc:0.98383\n",
      "[44]\tvalidation_0-logloss:0.03739\tvalidation_0-mcc:0.98382\n",
      "[45]\tvalidation_0-logloss:0.03739\tvalidation_0-mcc:0.98377\n",
      "[46]\tvalidation_0-logloss:0.03741\tvalidation_0-mcc:0.98376\n",
      "[47]\tvalidation_0-logloss:0.03741\tvalidation_0-mcc:0.98379\n",
      "[48]\tvalidation_0-logloss:0.03740\tvalidation_0-mcc:0.98381\n",
      "[49]\tvalidation_0-logloss:0.03738\tvalidation_0-mcc:0.98375\n",
      "[50]\tvalidation_0-logloss:0.03738\tvalidation_0-mcc:0.98377\n",
      "[51]\tvalidation_0-logloss:0.03736\tvalidation_0-mcc:0.98385\n",
      "[52]\tvalidation_0-logloss:0.03733\tvalidation_0-mcc:0.98382\n",
      "[53]\tvalidation_0-logloss:0.03732\tvalidation_0-mcc:0.98385\n",
      "[54]\tvalidation_0-logloss:0.03733\tvalidation_0-mcc:0.98385\n",
      "[55]\tvalidation_0-logloss:0.03733\tvalidation_0-mcc:0.98381\n",
      "[56]\tvalidation_0-logloss:0.03733\tvalidation_0-mcc:0.98384\n",
      "[57]\tvalidation_0-logloss:0.03730\tvalidation_0-mcc:0.98389\n",
      "[58]\tvalidation_0-logloss:0.03728\tvalidation_0-mcc:0.98387\n",
      "[59]\tvalidation_0-logloss:0.03726\tvalidation_0-mcc:0.98392\n",
      "[60]\tvalidation_0-logloss:0.03728\tvalidation_0-mcc:0.98394\n",
      "[61]\tvalidation_0-logloss:0.03726\tvalidation_0-mcc:0.98390\n",
      "[62]\tvalidation_0-logloss:0.03726\tvalidation_0-mcc:0.98388\n",
      "[63]\tvalidation_0-logloss:0.03726\tvalidation_0-mcc:0.98390\n",
      "[64]\tvalidation_0-logloss:0.03725\tvalidation_0-mcc:0.98389\n",
      "[65]\tvalidation_0-logloss:0.03726\tvalidation_0-mcc:0.98390\n",
      "[66]\tvalidation_0-logloss:0.03728\tvalidation_0-mcc:0.98388\n",
      "[67]\tvalidation_0-logloss:0.03727\tvalidation_0-mcc:0.98386\n",
      "[68]\tvalidation_0-logloss:0.03728\tvalidation_0-mcc:0.98389\n",
      "[69]\tvalidation_0-logloss:0.03728\tvalidation_0-mcc:0.98389\n",
      "[70]\tvalidation_0-logloss:0.03729\tvalidation_0-mcc:0.98389\n",
      "[71]\tvalidation_0-logloss:0.03729\tvalidation_0-mcc:0.98387\n",
      "[72]\tvalidation_0-logloss:0.03729\tvalidation_0-mcc:0.98386\n",
      "[73]\tvalidation_0-logloss:0.03731\tvalidation_0-mcc:0.98390\n",
      "[74]\tvalidation_0-logloss:0.03731\tvalidation_0-mcc:0.98389\n",
      "[75]\tvalidation_0-logloss:0.03730\tvalidation_0-mcc:0.98390\n",
      "[76]\tvalidation_0-logloss:0.03733\tvalidation_0-mcc:0.98392\n",
      "[77]\tvalidation_0-logloss:0.03734\tvalidation_0-mcc:0.98392\n",
      "[78]\tvalidation_0-logloss:0.03735\tvalidation_0-mcc:0.98393\n",
      "[79]\tvalidation_0-logloss:0.03738\tvalidation_0-mcc:0.98395\n",
      "[80]\tvalidation_0-logloss:0.03739\tvalidation_0-mcc:0.98390\n",
      "[81]\tvalidation_0-logloss:0.03739\tvalidation_0-mcc:0.98390\n",
      "[82]\tvalidation_0-logloss:0.03739\tvalidation_0-mcc:0.98390\n",
      "[83]\tvalidation_0-logloss:0.03741\tvalidation_0-mcc:0.98390\n",
      "[84]\tvalidation_0-logloss:0.03741\tvalidation_0-mcc:0.98391\n",
      "[85]\tvalidation_0-logloss:0.03742\tvalidation_0-mcc:0.98392\n",
      "[86]\tvalidation_0-logloss:0.03742\tvalidation_0-mcc:0.98394\n",
      "[87]\tvalidation_0-logloss:0.03742\tvalidation_0-mcc:0.98394\n",
      "[88]\tvalidation_0-logloss:0.03743\tvalidation_0-mcc:0.98393\n",
      "[89]\tvalidation_0-logloss:0.03745\tvalidation_0-mcc:0.98390\n",
      "[90]\tvalidation_0-logloss:0.03746\tvalidation_0-mcc:0.98390\n",
      "[91]\tvalidation_0-logloss:0.03747\tvalidation_0-mcc:0.98389\n",
      "[92]\tvalidation_0-logloss:0.03747\tvalidation_0-mcc:0.98387\n",
      "[93]\tvalidation_0-logloss:0.03746\tvalidation_0-mcc:0.98386\n",
      "[94]\tvalidation_0-logloss:0.03748\tvalidation_0-mcc:0.98390\n",
      "[95]\tvalidation_0-logloss:0.03748\tvalidation_0-mcc:0.98390\n",
      "[96]\tvalidation_0-logloss:0.03747\tvalidation_0-mcc:0.98389\n",
      "[97]\tvalidation_0-logloss:0.03748\tvalidation_0-mcc:0.98389\n",
      "[98]\tvalidation_0-logloss:0.03748\tvalidation_0-mcc:0.98392\n",
      "[99]\tvalidation_0-logloss:0.03750\tvalidation_0-mcc:0.98392\n",
      "[100]\tvalidation_0-logloss:0.03750\tvalidation_0-mcc:0.98391\n",
      "[101]\tvalidation_0-logloss:0.03750\tvalidation_0-mcc:0.98396\n",
      "[102]\tvalidation_0-logloss:0.03750\tvalidation_0-mcc:0.98394\n",
      "[103]\tvalidation_0-logloss:0.03751\tvalidation_0-mcc:0.98394\n",
      "[104]\tvalidation_0-logloss:0.03751\tvalidation_0-mcc:0.98393\n",
      "[105]\tvalidation_0-logloss:0.03751\tvalidation_0-mcc:0.98392\n",
      "[106]\tvalidation_0-logloss:0.03753\tvalidation_0-mcc:0.98392\n",
      "[107]\tvalidation_0-logloss:0.03753\tvalidation_0-mcc:0.98396\n",
      "[108]\tvalidation_0-logloss:0.03755\tvalidation_0-mcc:0.98398\n",
      "[109]\tvalidation_0-logloss:0.03755\tvalidation_0-mcc:0.98398\n",
      "[110]\tvalidation_0-logloss:0.03756\tvalidation_0-mcc:0.98396\n",
      "[111]\tvalidation_0-logloss:0.03756\tvalidation_0-mcc:0.98396\n",
      "[112]\tvalidation_0-logloss:0.03756\tvalidation_0-mcc:0.98394\n",
      "[113]\tvalidation_0-logloss:0.03757\tvalidation_0-mcc:0.98394\n",
      "[114]\tvalidation_0-logloss:0.03758\tvalidation_0-mcc:0.98394\n",
      "[115]\tvalidation_0-logloss:0.03758\tvalidation_0-mcc:0.98391\n",
      "[116]\tvalidation_0-logloss:0.03760\tvalidation_0-mcc:0.98391\n",
      "[117]\tvalidation_0-logloss:0.03762\tvalidation_0-mcc:0.98390\n",
      "[118]\tvalidation_0-logloss:0.03762\tvalidation_0-mcc:0.98388\n",
      "[119]\tvalidation_0-logloss:0.03763\tvalidation_0-mcc:0.98386\n",
      "[120]\tvalidation_0-logloss:0.03762\tvalidation_0-mcc:0.98389\n",
      "[121]\tvalidation_0-logloss:0.03762\tvalidation_0-mcc:0.98388\n",
      "[122]\tvalidation_0-logloss:0.03764\tvalidation_0-mcc:0.98389\n",
      "[123]\tvalidation_0-logloss:0.03765\tvalidation_0-mcc:0.98392\n",
      "[124]\tvalidation_0-logloss:0.03765\tvalidation_0-mcc:0.98392\n",
      "[125]\tvalidation_0-logloss:0.03767\tvalidation_0-mcc:0.98390\n",
      "[126]\tvalidation_0-logloss:0.03768\tvalidation_0-mcc:0.98390\n",
      "[127]\tvalidation_0-logloss:0.03769\tvalidation_0-mcc:0.98389\n",
      "[128]\tvalidation_0-logloss:0.03770\tvalidation_0-mcc:0.98390\n",
      "[129]\tvalidation_0-logloss:0.03770\tvalidation_0-mcc:0.98389\n",
      "[130]\tvalidation_0-logloss:0.03771\tvalidation_0-mcc:0.98392\n",
      "[131]\tvalidation_0-logloss:0.03773\tvalidation_0-mcc:0.98392\n",
      "[132]\tvalidation_0-logloss:0.03775\tvalidation_0-mcc:0.98394\n",
      "[133]\tvalidation_0-logloss:0.03776\tvalidation_0-mcc:0.98394\n",
      "[134]\tvalidation_0-logloss:0.03777\tvalidation_0-mcc:0.98393\n",
      "[135]\tvalidation_0-logloss:0.03777\tvalidation_0-mcc:0.98393\n",
      "[136]\tvalidation_0-logloss:0.03779\tvalidation_0-mcc:0.98392\n",
      "[137]\tvalidation_0-logloss:0.03780\tvalidation_0-mcc:0.98394\n",
      "[138]\tvalidation_0-logloss:0.03781\tvalidation_0-mcc:0.98392\n",
      "[139]\tvalidation_0-logloss:0.03781\tvalidation_0-mcc:0.98390\n",
      "[140]\tvalidation_0-logloss:0.03782\tvalidation_0-mcc:0.98393\n",
      "[141]\tvalidation_0-logloss:0.03783\tvalidation_0-mcc:0.98392\n",
      "[142]\tvalidation_0-logloss:0.03783\tvalidation_0-mcc:0.98394\n",
      "[143]\tvalidation_0-logloss:0.03783\tvalidation_0-mcc:0.98395\n",
      "[144]\tvalidation_0-logloss:0.03783\tvalidation_0-mcc:0.98394\n",
      "[145]\tvalidation_0-logloss:0.03785\tvalidation_0-mcc:0.98398\n",
      "[146]\tvalidation_0-logloss:0.03785\tvalidation_0-mcc:0.98399\n",
      "[147]\tvalidation_0-logloss:0.03788\tvalidation_0-mcc:0.98398\n",
      "[148]\tvalidation_0-logloss:0.03789\tvalidation_0-mcc:0.98394\n",
      "[149]\tvalidation_0-logloss:0.03789\tvalidation_0-mcc:0.98396\n",
      "[150]\tvalidation_0-logloss:0.03790\tvalidation_0-mcc:0.98394\n",
      "[151]\tvalidation_0-logloss:0.03791\tvalidation_0-mcc:0.98394\n",
      "[152]\tvalidation_0-logloss:0.03792\tvalidation_0-mcc:0.98395\n",
      "[153]\tvalidation_0-logloss:0.03792\tvalidation_0-mcc:0.98394\n",
      "[154]\tvalidation_0-logloss:0.03794\tvalidation_0-mcc:0.98394\n",
      "[155]\tvalidation_0-logloss:0.03794\tvalidation_0-mcc:0.98392\n",
      "[156]\tvalidation_0-logloss:0.03794\tvalidation_0-mcc:0.98389\n",
      "[157]\tvalidation_0-logloss:0.03794\tvalidation_0-mcc:0.98388\n",
      "[158]\tvalidation_0-logloss:0.03793\tvalidation_0-mcc:0.98388\n",
      "[159]\tvalidation_0-logloss:0.03794\tvalidation_0-mcc:0.98387\n",
      "[160]\tvalidation_0-logloss:0.03796\tvalidation_0-mcc:0.98390\n",
      "[161]\tvalidation_0-logloss:0.03796\tvalidation_0-mcc:0.98390\n",
      "[162]\tvalidation_0-logloss:0.03797\tvalidation_0-mcc:0.98390\n",
      "[163]\tvalidation_0-logloss:0.03797\tvalidation_0-mcc:0.98394\n",
      "[164]\tvalidation_0-logloss:0.03798\tvalidation_0-mcc:0.98394\n",
      "[165]\tvalidation_0-logloss:0.03799\tvalidation_0-mcc:0.98393\n",
      "[166]\tvalidation_0-logloss:0.03799\tvalidation_0-mcc:0.98394\n",
      "[167]\tvalidation_0-logloss:0.03800\tvalidation_0-mcc:0.98392\n",
      "[168]\tvalidation_0-logloss:0.03800\tvalidation_0-mcc:0.98394\n",
      "[169]\tvalidation_0-logloss:0.03801\tvalidation_0-mcc:0.98394\n",
      "[170]\tvalidation_0-logloss:0.03801\tvalidation_0-mcc:0.98393\n",
      "[171]\tvalidation_0-logloss:0.03802\tvalidation_0-mcc:0.98394\n",
      "[172]\tvalidation_0-logloss:0.03802\tvalidation_0-mcc:0.98395\n",
      "[173]\tvalidation_0-logloss:0.03802\tvalidation_0-mcc:0.98396\n",
      "[174]\tvalidation_0-logloss:0.03803\tvalidation_0-mcc:0.98398\n",
      "[175]\tvalidation_0-logloss:0.03804\tvalidation_0-mcc:0.98399\n",
      "[176]\tvalidation_0-logloss:0.03804\tvalidation_0-mcc:0.98401\n",
      "[177]\tvalidation_0-logloss:0.03805\tvalidation_0-mcc:0.98402\n",
      "[178]\tvalidation_0-logloss:0.03806\tvalidation_0-mcc:0.98398\n",
      "[179]\tvalidation_0-logloss:0.03806\tvalidation_0-mcc:0.98399\n",
      "[180]\tvalidation_0-logloss:0.03806\tvalidation_0-mcc:0.98401\n",
      "[181]\tvalidation_0-logloss:0.03808\tvalidation_0-mcc:0.98400\n",
      "[182]\tvalidation_0-logloss:0.03808\tvalidation_0-mcc:0.98399\n",
      "[183]\tvalidation_0-logloss:0.03809\tvalidation_0-mcc:0.98401\n",
      "[184]\tvalidation_0-logloss:0.03810\tvalidation_0-mcc:0.98398\n",
      "[185]\tvalidation_0-logloss:0.03810\tvalidation_0-mcc:0.98396\n",
      "[186]\tvalidation_0-logloss:0.03810\tvalidation_0-mcc:0.98396\n",
      "[187]\tvalidation_0-logloss:0.03811\tvalidation_0-mcc:0.98397\n",
      "[188]\tvalidation_0-logloss:0.03811\tvalidation_0-mcc:0.98397\n",
      "[189]\tvalidation_0-logloss:0.03811\tvalidation_0-mcc:0.98399\n",
      "[190]\tvalidation_0-logloss:0.03812\tvalidation_0-mcc:0.98399\n",
      "[191]\tvalidation_0-logloss:0.03812\tvalidation_0-mcc:0.98402\n",
      "[192]\tvalidation_0-logloss:0.03814\tvalidation_0-mcc:0.98401\n",
      "[193]\tvalidation_0-logloss:0.03814\tvalidation_0-mcc:0.98402\n",
      "[194]\tvalidation_0-logloss:0.03814\tvalidation_0-mcc:0.98403\n",
      "[195]\tvalidation_0-logloss:0.03815\tvalidation_0-mcc:0.98399\n",
      "[196]\tvalidation_0-logloss:0.03816\tvalidation_0-mcc:0.98397\n",
      "[197]\tvalidation_0-logloss:0.03818\tvalidation_0-mcc:0.98394\n",
      "[198]\tvalidation_0-logloss:0.03817\tvalidation_0-mcc:0.98396\n",
      "[199]\tvalidation_0-logloss:0.03818\tvalidation_0-mcc:0.98394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugph\\Ml\\s4e8\\venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [17:13:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC 0.9840858983233973\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2077964 entries, 0 to 2077963\n",
      "Columns: 135 entries, num__cap-diameter to cat__season_w\n",
      "dtypes: float64(135)\n",
      "memory usage: 2.1 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "smoothing = {}\n",
    "\n",
    "# for i in np.linspace(5,20,4):\n",
    "#     model(i)\n",
    "# model()\n",
    "model(9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cap-shape x cap-diameter median' in smoothing['feature names']:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840858983233973"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing[9.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * NEW BENCHMARK FOR ONE HOT ENCODING\n",
    "# 0.9843645395934322\n",
    "# One Hot Encoding only fit_transform train and spliting missing and noise : 0.9843650325175951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(sorted(smoothing.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding \n",
    "\n",
    "NaNs in categorical columns have their own feature after one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MCC 0.9841636261609926\n",
    "# 2. MCC 0.9842990664421013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * Target Encoding\n",
    "#  {np.float64(2.0): np.float64(0.984050532687097),\n",
    "#  np.float64(7.0): np.float64(0.9841408416248388),\n",
    "#  np.float64(1.0): np.float64(0.984153302705847),\n",
    "#  np.float64(8.0): np.float64(0.9842243023588968),\n",
    "#  np.float64(6.0): np.float64(0.9842284725563117),\n",
    "#  np.float64(10.0): np.float64(0.984234247240041),\n",
    "#  np.float64(3.0): np.float64(0.9842414180099538),\n",
    "#  np.float64(4.0): np.float64(0.984298975666255),\n",
    "#  np.float64(5.0): np.float64(0.9843180598293413),\n",
    "#  np.float64(9.0): np.float64(0.9843415677666381)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * One Hot Encoding\n",
    "# * One Hot Encoding = MCC 0.9845601293900792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# * With train, test, and validation set \n",
    "# * One Hot Encoding = MCC 0.9845601293900792\n",
    "# * Target Encoding Smoothing = 9.0 cv = 5: MCC 0.9843784324361466\n",
    "# * Target Encoding Smoothing = 9.0 cv = 10 : MCC 0.9844689041665822\n",
    "# * Target Encoding Category_encoders Smoothing = 9.0 : MCC 0.984527270385196\n",
    "# * Ordinal Encoding : MCC 0.9844821290074579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
